import geopandas as gpd
import matplotlib.pyplot as plt
import pandas as pd
from shapely.geometry import Point
from geopandas import GeoDataFrame

# Specify the path to the shapefile
path = r"../data/bgd_nhr_floods_barc"

# Read the shapefile into a GeoDataFrame
gdf = gpd.read_file(path)

# specify the path to the CSV file containing road data
path_roads = r"../data/_roads3.csv"

# Read the CSV file into a DataFrame
df = pd.read_csv(path_roads)

# Keep only the specified columns
df = df[['lon', 'lat', 'road', 'chainage']]

# Convert the 'df' DataFrame to a GeoDataFrame
geometry = [Point(xy) for xy in zip(df['lon'], df['lat'])]
df_geo = GeoDataFrame(df, geometry=geometry, crs="EPSG:4326")  # Ensure CRS matches gdf

# Perform a spatial join with gdf
merged_gdf = gpd.sjoin(df_geo, gdf, how="inner", predicate="intersects")

# Map the FLOODCAT values to adjust the categories
floodcat_mapping = {0: 0, 1: 3, 2: 2, 3: 1}  # Adjust 3 -> 1 and 1 -> 3
merged_gdf['FLOODCAT'] = merged_gdf['FLOODCAT'].map(floodcat_mapping)

# Filter for relevant FLOODCAT values (0, 1, 2, 3)
filtered_gdf = merged_gdf[merged_gdf['FLOODCAT'].isin([0, 1, 2, 3])]

# Group by 'road' and calculate the average FLOODCAT
average_flood_score = (
    filtered_gdf.groupby('road')
    .agg(avg_flood_score=('FLOODCAT', 'mean'))  # Calculate the average FLOODCAT
    .reset_index()
)

# Normalize the average flood score (0 corresponds to 0, 1 corresponds to 2)
average_flood_score['avg_flood_score'] = average_flood_score['avg_flood_score'] / 3

#only show the relevant columns
average_flood_score =  average_flood_score[['road', 'avg_flood_score']]

# Save the table to a CSV file
average_flood_score.to_csv("../data/processed_data/road_flood_scores.csv", index=False)

print("The normalized scores have been saved to '../data/processed_data/road_flood_scores.csv'.")


# Now for the bridges
path_bridges = r'../data/BMMS_overview.xlsx'
# Read the Excel file into a DataFrame
df_bridges = pd.read_excel(path_bridges)  

# Ensure the bridges DataFrame has latitude and longitude columns
df_bridges = df_bridges.rename(columns={"lat": "latitude", "lon": "longitude"})

# Convert the bridges DataFrame to a GeoDataFrame
geometry_bridges = [Point(xy) for xy in zip(df_bridges["longitude"], df_bridges["latitude"])]
gdf_bridges = GeoDataFrame(df_bridges, geometry=geometry_bridges, crs="EPSG:4326")  # Ensure CRS matches gdf_floods

# Reproject the bridges GeoDataFrame to match the flood GeoDataFrame CRS
gdf_bridges = gdf_bridges.to_crs(gdf.crs)

# Perform a spatial join between bridges and flood GeoDataFrame
merged_bridges_gdf = gpd.sjoin(gdf_bridges, gdf, how="inner", predicate="intersects")

# Filter for relevant FLOODCAT values (0, 1, 2, 3) in the merged GeoDataFrame
filtered_bridges_gdf = merged_bridges_gdf[merged_bridges_gdf['FLOODCAT'].isin([0, 1, 2, 3])]
filtered_bridges_gdf['FLOODCAT'] = filtered_bridges_gdf['FLOODCAT'].map(floodcat_mapping)

# Group by 'LRPName' and calculate the average FLOODCAT
average_flood_score_bridges = (
    filtered_bridges_gdf.groupby('LRPName')
    .agg(avg_flood_score=('FLOODCAT', 'mean'))  # Calculate the average FLOODCAT
    .reset_index()
)

# Normalize the average flood score (0 corresponds to 0, 1 corresponds to 2)
average_flood_score_bridges['avg_flood_score'] = average_flood_score_bridges['avg_flood_score'] / 3

# Only show the relevant columns
average_flood_score_bridges = average_flood_score_bridges[['LRPName', 'avg_flood_score']]

# Display the final table
print(average_flood_score_bridges)

# Save the table to a CSV file
average_flood_score_bridges.to_csv("../data/processed_data/avg_bridge_flood_scores.csv", index=False)

print("The normalized scores per LRPName have been saved to '../data/processed_data/bridge_flood_scores.csv'.")
